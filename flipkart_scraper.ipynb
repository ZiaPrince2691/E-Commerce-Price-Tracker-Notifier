{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19bba59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7fb1ce50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_data_coloumn(products, names, prices, links):\n",
    "    \n",
    "    for product in products:\n",
    "\n",
    "        try:\n",
    "            product_name = product.find('div', class_ = 'KzDlHZ').text\n",
    "        except:\n",
    "            product_name = np.nan\n",
    "\n",
    "        try:    \n",
    "            product_price_raw = product.find('div', class_ = 'Nx9bqj _4b5DiR')\n",
    "            product_price = int(product_price_raw.text[1:].replace(',' , ''))\n",
    "        except:\n",
    "            product_price = np.nan\n",
    "\n",
    "        try:\n",
    "            relative_link = product.find('a', class_ = 'CGtC98').get('href')\n",
    "            product_link = 'flipkart.com' + relative_link\n",
    "        except:\n",
    "            product_link = np.nan\n",
    "\n",
    "        names.append(product_name)\n",
    "        prices.append(product_price)\n",
    "        links.append(product_link)\n",
    "\n",
    "def scrape_data_grid(products, names, prices, links):\n",
    "    \n",
    "    for product in products:\n",
    "        try:\n",
    "            product_name = product.find('a', class_ = 'wjcEIp').get('title')\n",
    "        except:\n",
    "            product_name = np.nan\n",
    "\n",
    "        try:    \n",
    "            product_price_raw = product.find('div', class_ = 'Nx9bqj')\n",
    "            product_price = int(product_price_raw.text[1:].replace(',' , ''))\n",
    "        except:\n",
    "            product_price = np.nan\n",
    "\n",
    "        try:\n",
    "            relative_link = product.find('a', class_ = 'wjcEIp').get('href')\n",
    "            product_link = 'flipkart.com' + relative_link\n",
    "        except:\n",
    "            product_link = np.nan\n",
    "\n",
    "        names.append(product_name)\n",
    "        prices.append(product_price)\n",
    "        links.append(product_link)\n",
    "\n",
    "def scrape_data_from_page(html, names, prices, links):\n",
    "    \n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    products = soup.find_all('div', class_ = 'slAVV4')\n",
    "\n",
    "    if len(products) == 0:\n",
    "        products = soup.find_all('div', class_ = 'tUxRFH')\n",
    "        scrape_data_coloumn(products, names, prices, links)\n",
    "    else:\n",
    "        scrape_data_grid(products, names, prices, links)\n",
    "    \n",
    "def filter_negative_keywords(df, negative_keywords):\n",
    "    negative_keywords = negative_keywords.replace(' ', '')\n",
    "    negative_keywords = negative_keywords.replace(',', '|')\n",
    "\n",
    "    if not negative_keywords.strip():\n",
    "        return df\n",
    "    \n",
    "    print(negative_keywords)\n",
    "    df['Names'] = df['Names'].astype(str)\n",
    "    df = df[~df['Names'].str.contains(negative_keywords, case=False, na=False)]\n",
    "    return df\n",
    "\n",
    "def scrape_all_pages(driver, names, prices, links):\n",
    "    \n",
    "    while True :\n",
    "\n",
    "        old_data_length = len(names)\n",
    "        scrape_data_from_page(driver.page_source, names, prices, links)\n",
    "\n",
    "        next_btn = driver.find_elements(By.CLASS_NAME , '_9QVEpD')[-1]\n",
    "        time.sleep(1)\n",
    "\n",
    "        if len(names) == old_data_length:\n",
    "            break\n",
    "        \n",
    "        if next_btn.text == 'NEXT':\n",
    "            driver.execute_script(\"arguments[0].click();\", next_btn)\n",
    "            time.sleep(4)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "def get_data(names, prices, links, negative_keywords):\n",
    "    df = pd.DataFrame({\n",
    "        'Names' : names,\n",
    "        'Prices' : prices,\n",
    "        'Links' : links\n",
    "    } , index = [i for i in range(1,len(names)+1)])\n",
    "\n",
    "    df = df.dropna()\n",
    "    df = filter_negative_keywords(df, negative_keywords)\n",
    "    df = df.sort_values(by='Prices')\n",
    "    df.index = [i for i in range(1,len(df)+1)]\n",
    "\n",
    "    return df\n",
    "\n",
    "def create_files(df, product , max_budget , min_budget):\n",
    "\n",
    "    product_name = product.replace(' ' , '_')\n",
    "    df = df[df['Prices'] <= float(max_budget)] \n",
    "    df = df[df['Prices'] >= float(min_budget)] \n",
    "    df.to_csv(f'{product_name}s_under_{max_budget}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c36f7764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please wait.....\n",
      " It may take few minutes.....\n",
      " Thanks for your patience.....\n"
     ]
    }
   ],
   "source": [
    "product           = input('     What do you want to buy? : ')\n",
    "max_budget        = input(' What is your maximum budget? : ')\n",
    "min_budget        = input(' What is your minimum budget? : ')\n",
    "negative_keywords = input(\"Enter Keywords you don't want : \")\n",
    "print('Please wait.....\\n It may take few minutes.....\\n Thanks for your patience.....')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "681eb602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mouse- Buy Products Online at Best Price in India - All Categories | Flipkart.com\n"
     ]
    }
   ],
   "source": [
    "url = f\"https://www.flipkart.com/search?q={product}&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off&p%5B%5D=facets.price_range.from%3D{min_budget}&p%5B%5D=facets.price_range.to%3D{max_budget}\"\n",
    "\n",
    "names = []\n",
    "prices = []\n",
    "links = []\n",
    "\n",
    "# options = Options()\n",
    "# options.add_argument('--headless')\n",
    "# driver = webdriver.Chrome(options=options)\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(url)\n",
    "time.sleep(2)\n",
    "print(driver.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60dcf5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape_all_pages(driver, names, prices, links)\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b6ef76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_data(names, prices, links, negative_keywords)\n",
    "create_files(df, product , max_budget , min_budget)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
